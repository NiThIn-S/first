{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing on Amazon's Fine Food Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon's Fine Food reviews dataset :  https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.\n",
    "   - Number of reviews: 568,454\n",
    "   - Number of users: 256,059\n",
    "   - Number of products: 74,258\n",
    "   - Timespan: Oct 1999 - Oct 2012\n",
    "   - Number of Attributes/Columns in data: 10(including class attribute)\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "   - Id\n",
    "   - ProductId - unique identifier for the product\n",
    "   - UserId - unqiue identifier for the user\n",
    "   - ProfileName\n",
    "   - HelpfulnessNumerator - number of users who found the review helpful\n",
    "   - HelpfulnessDenominator - Total number of users who indicated whether they found the review helpful or not\n",
    "   - Time - timestamp for the review\n",
    "   - Summary - brief summary of the review\n",
    "   - Text - text of the review\n",
    "   - Score(Class Label) - rating between 1 and 5 (rating 1 & 2 is negative, rating 4 & 5 is positive and rating 3 is neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "   - Complete a data cleaning and data preprocessing and store it in a separate database, for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re, os, sqlite3,pickle\n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer as snow\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the class-label 'Score' contains 5 different value including 3 which is neither positive nor negative review. For this study we omit 3 star rating and change the rest to positive(4 & 5 star) as 1 or negative(1 & 2 star) as 0  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing class label to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 10)\n"
     ]
    }
   ],
   "source": [
    "link = sqlite3.connect('../database.sqlite')\n",
    "con_data= pd.read_sql_query(''' SELECT * FROM REVIEWS WHERE SCORE != 3''',link)\n",
    "print(con_data.shape)\n",
    "link.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525814,), (525814, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=con_data['Score']\n",
    "con_data['Score'] = list(map(lambda x: 1 if x>3 else 0,d ))    # changing the Score values to 1(positive) \\\n",
    "con_data['Score'].shape,con_data.shape                         # and 0(negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Id   ProductId          UserId                      ProfileName  \\\n",
       " 0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       " 1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       " 2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       " \n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       " 0                     1                       1      1  1303862400   \n",
       " 1                     0                       0      0  1346976000   \n",
       " 2                     1                       1      1  1219017600   \n",
       " \n",
       "                  Summary                                               Text  \n",
       " 0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       " 1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       " 2  \"Delight\" says it all  This is a confection that has been around a fe...  ,\n",
       " 939340800)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_data.head(3),con_data.Time.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525814, 10), (364173, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data = con_data.sort_values('ProductId', axis=0, ascending=True, \n",
    "                                   inplace=False, kind='quicksort', na_position='last')  # Deduplication\n",
    "final_data = sorted_data.drop_duplicates(subset={'UserId','ProfileName','Time','Text'}, \n",
    "                                         keep='first', inplace=False)\n",
    "sorted_data.shape,final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data[final_data['HelpfulnessDenominator'] >= final_data['HelpfulnessNumerator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ProductId's B00004CI84, B00004CXX9 - belongs to the movie called 'Beetle Juice'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363980, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = final_data[final_data['ProductId'] != 'B00004CXX9' ]  \n",
    "cleaned_data = final[final['ProductId'] != 'B00004CI84' ]\n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306886 positive reviews and 57094 negative reviews\n"
     ]
    }
   ],
   "source": [
    "a,b=cleaned_data.Score.value_counts()\n",
    "print('%d positive reviews and %d negative reviews'%(a,b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Conclusion:\n",
    "   - The dataset is highly imbalanced "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId            ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL        shari zychinski   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U                  Tracy   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4  sally sue \"sally sue\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "138706                     0                       0      1   939340800   \n",
       "138688                     1                       1      1  1194739200   \n",
       "138689                     1                       1      1  1191456000   \n",
       "\n",
       "                                           Summary  \\\n",
       "138706                   EVERY book is educational   \n",
       "138688  Love the book, miss the hard cover version   \n",
       "138689               chicken soup with rice months   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  I grew up reading these Sendak books, and watc...  \n",
       "138689  This is a fun way for children to learn their ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"haven't\", 'weren', 'herself', 'himself', 'he', 'each', 'own', 'won', 'on', 'doesn', 'no', \"aren't\", 'am', 'once', 'in', 'too', 'not', 'mightn', 'other', 'hers', \"should've\", 'those', 't', 'myself', 'all', 'some', 'hadn', 'is', 're', 'did', 'then', 'from', 's', 'where', 'now', \"doesn't\", 'who', 'are', 'our', 'themselves', 'ain', 'don', 'the', 'as', 'mustn', 'if', \"hasn't\", 'below', 'out', 'will', 'has', 'wasn', 'o', 'these', 'haven', 'shouldn', 'it', 'whom', 'both', 've', \"needn't\", 'again', 'm', 'couldn', 'until', 'further', \"couldn't\", 'a', \"it's\", 'more', 'having', 'do', \"mightn't\", 'this', 'while', \"shan't\", 'yourselves', 'needn', 'only', 'didn', 'after', 'between', 'isn', 'about', 'against', 'does', 'there', 'his', \"wasn't\", 'theirs', 'doing', 'before', 'ma', 'an', 'and', 'ours', 'can', 'into', 'why', \"hadn't\", \"that'll\", \"shouldn't\", 'being', 'their', 'same', \"weren't\", 'ourselves', 'was', 'my', \"isn't\", 'under', 'we', 'wouldn', 'to', \"wouldn't\", 'been', 'up', 'few', \"she's\", 'nor', 'yourself', 'such', 'him', 'aren', 'for', 'itself', 'her', 'hasn', \"you'll\", \"didn't\", 'have', 'but', 'here', 'during', 'they', 'you', 'down', \"don't\", \"won't\", 'its', 'had', 'how', 'off', 'of', 'should', 'above', 'any', 'so', 'when', 'y', 'by', 'which', 'what', 'at', 'd', 'she', \"you'd\", 'because', 'most', 'shan', 'your', 'i', 'them', 'that', 'very', 'or', 'with', 'than', 'were', 'be', 'just', \"you've\", \"mustn't\", 'me', 'over', 'through', 'll', 'yours', \"you're\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))    #initializing stopwords as a set\n",
    "print(stop)       \n",
    "len(stop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removing all the negative words from stopword set and Storing it in seperate set called nstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstop={'no','not','nor'}\n",
    "for el in stop:\n",
    "    if (\"n't\" in el):\n",
    "        nstop.add(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stop - nstop \n",
    "len(stop)                                    #stop = stopwords without negative words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(x):\n",
    "    c = re.compile('<.*?>')                 \n",
    "            # Removing all the html tags if present and replacing with 'space'\n",
    "    cleaned = re.sub(c,' ', x)\n",
    "    return cleaned\n",
    "\n",
    "def cleanpun(x):\n",
    "    c = re.sub(r'[?|!|\\'|\"|#]',r'',x)        \n",
    "            # removing single quotes without replacing any character \\ \n",
    "            #  is essential in  preserving sentiment words\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/|\\n]',r' ',c)\n",
    "    return  cleaned.lower()                  \n",
    "            # returning with lower case\n",
    "\n",
    "sno =snow('english')                        \n",
    "            #initializing snowballstemmer as sno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wouldnt', 'shant', 'shouldnt', 'hadnt', 'neednt', 'no', 'mightnt', 'werent', 'wont', 'doesnt', 'not', 'nor', 'isnt', 'dont', 'couldnt', 'arent', 'wasnt', 'mustnt', 'didnt', 'hasnt', 'havent'}\n"
     ]
    }
   ],
   "source": [
    "n=set(map(cleanpun,nstop))\n",
    "print(n,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./nstop.pickle', 'wb') as f:\n",
    "    pickle.dump(n, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cleaning_data(clean_data,stem1):\n",
    "    \"\"\"\n",
    "    Performing data cleaning and stemming if necessary.\n",
    "    \"\"\"\n",
    "    i=0\n",
    "    words = ' '\n",
    "    empty1 = []\n",
    "    \n",
    "    for sent in tqdm(clean_data):   \n",
    "                    #tqdm for progress bar\n",
    "        e2=[]   \n",
    "        sentence = cleanhtml(sent)                 \n",
    "                    # cleaning html tags\n",
    "        sentence = cleanpun(sentence)              \n",
    "                    # cleaning all punctuation and returning all lowercase\n",
    "        for word in sentence.split():             \n",
    "                    # getting a word in sentence separated by space \n",
    "            \n",
    "            if ((len(word) > 2) & (word.isalpha() ) & (word not in stop )): \n",
    "                    # checking length, authenticity and if the given word is a stopword\n",
    "                if(stem1):    \n",
    "                    s= sno.stem(word).encode('utf8')   \n",
    "                        # snowball stemming \n",
    "                else:\n",
    "                    s=word.encode('utf8')\n",
    "                e2.append(s)\n",
    "                 \n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            words = b' '.join(e2)     \n",
    "                    # joinning all the words by removing 'b' to form the sentence structure.\n",
    "        i= i+1  \n",
    "        empty1.append(words)                 \n",
    "                    # list of sll processed sentence\n",
    "    return empty1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing review 'Text' feature with stemming and storing it as 'c_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241e8a5cd71b478ba32e68821b11d9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=363980), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['c_text']= cleaning_data(\n",
    "                        clean_data=cleaned_data['Text'].values,\n",
    "                        stem1=True)                  \n",
    "     \n",
    "cleaned_data['c_text']=cleaned_data['c_text'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing review 'Summary' feature with stemming and storing it as 'c_summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8d1cd1e7f84df3814e38884d4ee04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=363980), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['c_summary']= cleaning_data(\n",
    "                        clean_data=cleaned_data['Summary'].values,\n",
    "                        stem1=True)                  \n",
    "\n",
    "cleaned_data['c_summary']=cleaned_data['c_summary'].str.decode('utf-8')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing review 'Text' feature without stemming and storing it as 'nostem_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a93306ca6f4afab0e30b22c3962ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=363980), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['nostem_text']= cleaning_data(\n",
    "                            clean_data=cleaned_data['Text'].values,\n",
    "                            stem1=False)                  \n",
    "\n",
    "cleaned_data['nostem_text']=cleaned_data['nostem_text'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  preprocessing review 'Summary' feature without stemming and storing it as 'nostem_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8318483bdf68413db3d2e1914fcd163e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=363980), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['nostem_summary']= cleaning_data(\n",
    "                        clean_data=cleaned_data['Summary'].values,\n",
    "                        stem1=False)                  \n",
    "           \n",
    "cleaned_data['nostem_summary']=cleaned_data['nostem_summary'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text', 'c_text',\n",
       "       'c_summary', 'nostem_text', 'nostem_summary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363980, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "939340800"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_data.shape)\n",
    "cleaned_data.Time.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "link = sqlite3.connect('cleaned_reviews.sqlite')        \n",
    "c=link.cursor()\n",
    "link.text_factory = str\n",
    "cleaned_data.to_sql('creviews', link, if_exists='replace', index=False)\n",
    "link.close()                                 \n",
    "            #saving all the data in a file called \"cleaned_reviews.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "   - Amazon fine food review data has been cleaned and stored in sql database called 'cleaned_reviews.sqlite'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
